{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y is the t+k periods return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ideas \n",
    "vectorize bid/asks, turn _Rate into spreads, or group by unique prices\n",
    "Random Forest\n",
    "use KDE to find joint distribution of price and volume\n",
    "Partition y into those y that increases, stays the same, decreases, then predict the magnitude\n",
    "Use k-means unsupervised ot do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-training.csv\")\n",
    "df.iloc[:,15:30] = df.iloc[:,15:30].fillna(0)\n",
    "#df.iloc[:,45:60] = df.iloc[:,45:60].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = ['ask,]\n",
    "\n",
    "lr = LinearRegression()\n",
    "    \n",
    "X_train = df[features].values.reshape(-1,len(features))\n",
    "y_train = df['y'].values.reshape(-1,)\n",
    "print(cross_val_score(lr,X_train,y_train,cv=3,scoring='r2').mean())\n",
    "lr.fit(X_train,y_train)\n",
    "print(\"In sample: \",lr.score(X_train,y_train))\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model =sm.OLS(y_train,sm.add_constant(X_train))\n",
    "model.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topLevel =['askRate0','askRate1','askRate2','bidRate0','bidRate1','bidRate2',\n",
    "                   'askSize0','askSize1','askSize2','bidSize0','bidSize1','bidSize2',]\n",
    "\n",
    "diffs = df[topLevel].diff(1)\n",
    "diffs2 = df[topLevel].diff(2)\n",
    "diffs3 = df[topLevel].diff(3)\n",
    "newcolumns = []\n",
    "newcolumns2 = []\n",
    "newcolumns3 =[]\n",
    "for x in diffs.columns:\n",
    "    newcolumns += [x+str('Diff')]\n",
    "    newcolumns2 += [x+str('Diff2')]\n",
    "    newcolumns3 += [x+str('Diff3')]\n",
    "    \n",
    "diffs.columns = newcolumns\n",
    "diffs2.columns = newcolumns2\n",
    "diffs3.columns = newcolumns3\n",
    "df_copy = pd.concat([df[topLevel],\n",
    "                     diffs[['askSize0Diff','bidSize0Diff','askRate0Diff','bidRate0Diff']],\n",
    "                     diffs2[['askSize0Diff2','bidSize0Diff2','askRate0Diff2','bidRate0Diff2',\n",
    "                             'askRate1Diff2','bidRate1Diff2','askRate2Diff2','bidRate2Diff2']],\n",
    "                     diffs3[['askSize0Diff3','bidSize0Diff3','askRate0Diff3','bidRate0Diff3',\n",
    "                            'askRate1Diff3','bidRate1Diff3','bidRate2Diff3']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df_copy):\n",
    "    #Price related features\n",
    "    df = df_copy.copy()\n",
    "#     #df['spread'] = df['askRate0'] - df['bidRate0'] #difference between best ask and best bid, current liquidity\n",
    "#     df['price'] = (df['askRate0'] + df['bidRate0'])/2 # mean of best ask and best bid\n",
    "    \n",
    "#     for i in range(15):\n",
    "#         df['askRate'+str(i)] -= df['price']\n",
    "#         df['bidRate'+str(i)] -= df['price']\n",
    "#     df['modeAskDepth'] =  df.iloc[:,15:30].idxmax(axis=1).apply(lambda x : int(x[7:]))\n",
    "#     df['modeBidDepth'] =  df.iloc[:,45:60].idxmax(axis=1).apply(lambda x : int(x[7:]))\n",
    "        \n",
    "    #volume related features\n",
    "#     df['totalAskVolume'] = df.iloc[:,15:30].sum(axis=1)\n",
    "#     df['totalBidVolume'] = df.iloc[:,45:60].sum(axis=1) \n",
    "#     df['totalVolumeDiff'] = df['totalAskVolume'] - df['totalBidVolume'] \n",
    "    \n",
    "    \n",
    "    for i in range(3):\n",
    "        df['imbalance'+str(i)] = (df['askSize'+str(i)] - df['bidSize'+str(i)]) / (df['askSize'+str(i)] + df['bidSize'+str(i)])\n",
    "        df['volumeDiff'+str(i)] = df['askSize'+str(i)] - df['bidSize'+str(i)]\n",
    "        df['priorAskSize'+str(i)] = (df['askSize'+str(i)] - df_copy['askSize'+str(i)+'Diff']) \n",
    "        df['priorBidSize'+str(i)] = (df['bidSize'+str(i)] - df_copy['bidSize'+str(i)+'Diff']) \n",
    "        df['priorAskRate'+str(i)] = df['askRate'+str(i)] - df['askRate'+str(i)+'Diff']\n",
    "        df['priorBidRate'+str(i)] = df['bidRate'+str(i)] - df['bidRate'+str(i)+'Diff']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "df_copy = transform(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_copy.corrwith(df['y']).abs().sort_values(ascending=False).head(16)\n",
    "\n",
    "# df_copy[['imbalance0','priorImbalance0','imbalance1','priorImbalance1','volumeDiff0','askSize0','imbalance2','priorImbalance2',\n",
    "#  'priorAskSize0','bidSize0','volumeDiff1','priorImbalance3','askSize1','imbalance3','priorAskSize1','priorBidSize0','priorImbalance4']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_copy['dPrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = ['imbalance0','imbalance1','imbalance2','imbalance3',\n",
    "            'volumeDiff0','volumeDiff1','volumeDiff2','volumeDiff3',]\n",
    "\n",
    "lr = LinearRegression()\n",
    "    \n",
    "X_train = df_copy.iloc[1:][features].values.reshape(-1,len(features))\n",
    "y_train = df_copy.iloc[1:]['y'].values.reshape(-1,)\n",
    "print(cross_val_score(lr,X_train,y_train,cv=3,scoring='r2').mean())\n",
    "lr.fit(X_train,y_train)\n",
    "print(\"In sample: \",lr.score(X_train,y_train))\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model =sm.OLS(y_train,sm.add_constant(X_train))\n",
    "model.fit().summary()\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(lr, '../XTXStarterKit-master/python/LinearRegression.pkl')\n",
    "joblib.dump(lr, 'model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(np.array(df_copy.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_copy.corrwith(df['y']).abs().sort_values(ascending=False).head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['askSize0Delta'] = df_copy['askSize0'] / df_copy['priorAskSize0']\n",
    "df_copy['bidSize0Delta'] = df_copy['bidSize0'] / df_copy['priorBidSize0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = ['askSize0','askSize1','askSize2',\n",
    "            'bidSize0','bidSize1','bidSize2',\n",
    "           'askSize0Diff3','bidSize0Diff3'] \n",
    "X_train = df_copy[features].values.reshape(-1,len(features))\n",
    "y_train = df['y'].values.reshape(-1,)\n",
    "\n",
    "\n",
    "\n",
    "xgbr = XGBRegressor(n_estimators=100,\n",
    "                    max_depth=3,\n",
    "                    n_jobs=2,\n",
    "                    tree_method=\"hist\",\n",
    "                    learning_rate = 0.05,\n",
    "                    base_score =0,\n",
    "                    objective=\"reg:squarederror\",)\n",
    "print(\"Cross val score: \",cross_val_score(xgbr,X_train,y_train,cv=3,scoring='r2').mean())\n",
    "\n",
    "\n",
    "xgbr.fit(X_train,y_train)\n",
    "xgb.plot_importance(xgbr)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "df['preds'] = xgbr.predict(X_train)\n",
    "print(\"In sample score: \",r2_score(y_train,df['preds']))\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(xgbr, '../XTXStarterKit-master/python/model.pkl')\n",
    "joblib.dump(xgbr, 'model.pkl')\n",
    "\n",
    "#Cross val score:  0.016362549494740402, In sample score:  0.020114822435111646\n",
    "#n_estimators,max_depth=3, features = [askSize0, bidSize0, askSize1, bidSize1,askSize2,bidSize2] , auto, learning_rate = 0.05\n",
    "\n",
    "#hist - Cross val score:  0.01627794302323841, In sample score:  0.020058962676913983\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(xgbr, '../XTXStarterKit-master/python/model.pkl')\n",
    "joblib.dump(xgbr, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('model.pkl')\n",
    "model.predict([1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['imbalance0','imbalance1','imbalance2']\n",
    "X_train = df_copy[features].values\n",
    "y_train = df_copy['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 15:20:18.409396 4434474432 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0813 15:20:18.806107 4434474432 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2249998/2249998 [==============================] - 33s 15us/sample - loss: 0.4961 - coeff_determination: 0.0105\n",
      "Epoch 2/10\n",
      " 441000/2249998 [====>.........................] - ETA: 27s - loss: 0.4959 - coeff_determination: 0.0122"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM,SimpleRNN\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    \n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "\n",
    "features = ['askSize0','bidSize0']\n",
    "\n",
    "timestep = 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df['y'].values.reshape(-1,)[timestep-1:]\n",
    "X = np.array(df[features].values).reshape(-1,len(features))\n",
    "X = np.concatenate([X[x:x+timestep,:] for x in range(X.shape[0]-1)])\n",
    "X = X.reshape(2999999-timestep+1,timestep,len(features))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)\n",
    "    \n",
    "                   \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(100,input_shape=(timestep,len(features))))\n",
    "model.add(tf.keras.layers.Dense(100 ,activation=tf.nn.relu))\n",
    "# model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse', \n",
    "              metrics=[coeff_determination])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"Validation :\", model.evaluate(X_test,y_test,3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array([[1,1],[1,1]]).reshape(1,2,2))[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
