{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset represents a order book for an asset over a long period of time, with bids and ask orders and their respective volume, with askRate0 being the best ask and bidRate0 being the best bid. Task is to train a model that predicts the future price movement of that asset.\n",
    "\n",
    "## best submission - xgboost #0.02025 [askSize0, bidSize0, askSize1, bidSize1,askSize2,bidSize2] \n",
    "### submission 9 - 0.01945 Linear Regression using ['pressure0,pressure1,pressure2']\n",
    "## submission 10-  0.02046 Linear Regression using ['pressure0','pressure1','pressure2','pressure3','volumeDiff0','volumeDiff1','volumeDiff2','volumeDiff3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-training.csv\")\n",
    "#Represents an order book with depth of up to n = 14, \n",
    "#2999,999 rows, 60 features, 1GB\n",
    "df.iloc[:,15:30] = df.iloc[:,15:30].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df_copy):\n",
    "    #Price related features\n",
    "    df = df_copy.copy()\n",
    "    #df['spread'] = df['askRate0'] - df['bidRate0'] #difference between best ask and best bid, current liquidity\n",
    "    df['price'] = (df['askRate0'] + df['bidRate0'])/2 # mean of best ask and best bid\n",
    "    \n",
    "    for i in range(15):\n",
    "        df['askRate'+str(i)] -= df['price']\n",
    "        df['bidRate'+str(i)] -= df['price']\n",
    "        \n",
    "    #volume related features\n",
    "    df['totalAskVolume'] = df.iloc[:,15:30].sum(axis=1)\n",
    "    df['totalBidVolume'] = df.iloc[:,45:60].sum(axis=1) \n",
    "    df['totalVolumeDiff'] = df['totalAskVolume'] - df['totalBidVolume'] \n",
    "    \n",
    "    \n",
    "    #\n",
    "    df['modeAskDepth'] =  df.iloc[:,15:30].idxmax(axis=1).apply(lambda x : int(x[7:]))\n",
    "    df['modeBidDepth'] =  df.iloc[:,45:60].idxmax(axis=1).apply(lambda x : int(x[7:]))\n",
    "    \n",
    "    \n",
    "    for i in range(10):\n",
    "        df['pressure'+str(i)] = df['askSize'+str(i)] / (df['askSize'+str(i)] + df['bidSize'+str(i)])\n",
    "        df['imbalance'+str(i)] = (df['askSize'+str(i)] - df['bidSize'+str(i)]) / (df['askSize'+str(i)] + df['bidSize'+str(i)])\n",
    "        df['volumeDiff'+str(i)] = df['askSize'+str(i)] - df['bidSize'+str(i)]\n",
    "        \n",
    "    return df\n",
    "    \n",
    "\n",
    "    #ideas - vectorize bid/asks\n",
    "df_copy = transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trial_features(df_copy):\n",
    "    df = df_copy.copy()\n",
    "    #mean, var,skew\n",
    "#     df['priceVar'] = 0\n",
    "#     df['priceSkew'] = 0\n",
    "    df['weightedAskPrice'] = 0\n",
    "    df['weightedBidPrice'] = 0\n",
    "    df['askPriceVar'] = 0\n",
    "    df['bidPriceVar'] = 0\n",
    "    df['askPriceSkew'] = 0\n",
    "    df['bidPriceSkew'] = 0\n",
    "    for i in range(15):\n",
    "#         df['priceVar'] += np.square(df['bidRate'+str(i)] -df['price'])  * df['bidSize'+str(i)]\n",
    "#         df['priceVar'] += np.square((df['askRate'+str(i)] -df['price']).fillna(0)) * df['askSize'+str(i)].fillna(0)\n",
    "        df['weightedAskPrice'] += df['askRate'+str(i)].fillna(0) * df['askSize'+str(i)]\n",
    "        df['weightedBidPrice'] += df['bidRate'+str(i)] * df['bidSize'+str(i)]\n",
    "\n",
    "#         df['priceSkew'] += np.power(df['bidRate'+str(i)] -df['price'],3) * df['bidSize'+str(i)]\n",
    "#         df['priceSkew'] += np.power((df['askRate'+str(i)] -df['price']).fillna(0),3) * df['askSize'+str(i)]\n",
    "    df['weightedAskPrice'] /= df['totalAskVolume']\n",
    "    df['weightedBidPrice'] /= df['totalAskVolume']\n",
    "    \n",
    "    for i in range(15):\n",
    "        df['askPriceVar'] += np.square((df['askRate'+str(i)] - df['weightedAskPrice']).fillna(0)) * df['askSize'+str(i)]\n",
    "        df['askPriceSkew'] += np.power((df['askRate'+str(i)] - df['weightedAskPrice']).fillna(0),3) * df['askSize'+str(i)]\n",
    "        df['bidPriceVar'] += np.square(df['bidRate'+str(i)] - df['weightedBidPrice']) * df['bidSize'+str(i)]\n",
    "        df['bidPriceSkew'] += np.power(df['bidRate'+str(i)] - df['weightedBidPrice'],3) * df['bidSize'+str(i)]\n",
    "    \n",
    "    df['askPriceVar'] /= df['totalAskVolume']\n",
    "    df['askPriceStd'] = np.sqrt(df['askPriceVar'])\n",
    "    df['bidPriceVar'] /= df['totalBidVolume']\n",
    "    df['bidPriceStd'] = np.sqrt(df['bidPriceVar'])\n",
    "    df['askPriceSkew'] = df['askPriceSkew'].fillna(0)\n",
    "    df['askPriceSkew'] /= (np.power(df['askPriceStd'],3) * df['totalAskVolume'])\n",
    "    df['bidPriceSkew'] /= (np.power(df['bidPriceStd'],3) * df['totalBidVolume'])\n",
    "    \n",
    "    df_copy['askPriceDiff'] = df_copy['weightedAskPrice'] - df_copy['price'] \n",
    "    df_copy['bidPriceDiff'] = df_copy['weightedBidPrice'] - df_copy['price'] \n",
    "        \n",
    "#     df['priceVar'] = df['priceVar'] / (df['totalAskVolume'] + df['totalBidVolume'])\n",
    "#     df['priceStd'] = np.sqrt(df['priceVar'])\n",
    "#     df['priceSkew'] = df['priceSkew'] / ((df['totalAskVolume'] + df['totalBidVolume']) * np.power(df['priceStd'],3))\n",
    "    return df\n",
    "\n",
    "df_copy = trial_features(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_copy.corrwith(df['y']).abs().sort_values(ascending=False).head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression,HuberRegressor \n",
    "#from sklearn.linear_model import PassiveAggressiveRegressor, ,TheilSenRegressor,SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "features = ['pressure0','pressure1','pressure2','pressure3',\n",
    "            'volumeDiff0','volumeDiff1','volumeDiff2','volumeDiff3']\n",
    "\n",
    "df_copy2 = df_copy[features+['y']].drop_duplicates()\n",
    "#df_copy2 = df_copy\n",
    "X_train = np.array(df_copy2[features]).reshape(-1,len(features))\n",
    "y_train = np.array(df_copy2['y']).reshape(-1,)\n",
    "\n",
    "lr = HuberRegressor()\n",
    "\n",
    " #best bid vol, best ask vol\n",
    "scores = cross_val_score(lr,X_train,y_train,cv=2,scoring='r2')\n",
    "print(\"Cross Val score: \", scores.mean())\n",
    "lr.fit(X_train,y_train)\n",
    "print(\"In sample score: \",lr.score(X_train,y_train))\n",
    "print(\"Coefs: \",lr.coef_)\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(lr, '../XTXStarterKit-master/python/LinearRegression.pkl')\n",
    "# joblib.dump(lr, 'LinearRegression.pkl')\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model =sm.OLS(y_train,sm.add_constant(X_train))\n",
    "model.fit().summary()\n",
    "\n",
    "#Huber Loss - Cross Val score:  0.015652126650498255,In sample 0.015881198921535056, drop duplicates \n",
    "#features = ['pressure0','pressure1','pressure2','pressure3','volumeDiff0','volumeDiff1','volumeDiff2','volumeDiff3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df_copy = df\n",
    "features = ['askSize0', 'bidSize0', 'askSize1', 'bidSize1','askSize2','bidSize2','modeAskDepth'] \n",
    "X_train = df_copy[features].values.reshape(-1,len(features))\n",
    "y_train = df_copy['y'].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "params = {'max_depth':2,'n_estimators':150,'learning_rate':0.05}\n",
    "xgbr = XGBRegressor(max_depth=params['max_depth'],\n",
    "                    n_estimators=params['n_estimators'],\n",
    "                    n_jobs=2,\n",
    "                    learning_rate = params['learning_rate'],\n",
    "                    objective=\"reg:squarederror\",)\n",
    "print(\"Cross val score: \",cross_val_score(xgbr,X_train,y_train,cv=3,scoring='r2').mean())\n",
    "\n",
    "#0.02025 on test set with [askSize0, bidSize0, askSize1, bidSize1,askSize2,bidSize2] \n",
    "#0.015488818975168683 cross val two folds\n",
    "xgbr.fit(X_train,y_train)\n",
    "xgb.plot_importance(xgbr)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "df['preds'] = xgbr.predict(X_train)\n",
    "print(\"In sample score: \",r2_score(y_train,df['preds']))\n",
    "\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(xgbr, '../XTXStarterKit-master/python/model.pkl')\n",
    "# joblib.dump(xgbr, 'model.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df.iloc[0,0:15],df.iloc[0,15:30])\n",
    "plt.bar(df.iloc[0,30:45],df.iloc[0,45:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "fig=plt.figure()\n",
    "fig.set_size_inches(15,7.5)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([1600,1800])\n",
    "axes.set_ylim([0,150])\n",
    "\n",
    "\n",
    "\n",
    "#ax.set_xlim(-1600,1800)\n",
    "#ax.setylim(0,200)\n",
    "\n",
    "n=10000 #Number of frames\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    fig.clear()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([1600,1640])\n",
    "    axes.set_ylim([0,150])\n",
    "    y=df.iloc[i,15:30]\n",
    "    x=df.iloc[i,0:15]\n",
    "    plt.bar(x,y)\n",
    "    y=df.iloc[i,45:60]\n",
    "    x=df.iloc[i,30:45]\n",
    "    plt.bar(x,y)\n",
    "    \n",
    "    \n",
    "\n",
    "anim=animation.FuncAnimation(fig,animate,repeat=False,blit=False,frames=n,\n",
    "                             interval=10)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Writer = animation.writers['ffmpeg']\n",
    "# writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "# anim.save('orderbook.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint distribution of bid asks\n",
    "kde on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xgb.plot_tree(xgbr,ax=ax,num_trees=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp =MLPRegressor(hidden_layer_sizes=(100,3),alpha=0.0001,learning_rate_init=0.5,\n",
    "                  max_iter=50,warm_start=True,n_iter_no_change=10,batch_size=1000)\n",
    "features = ['askSize0','bidSize0']\n",
    "X_train = np.array(df_copy[features]).reshape(-1,len(features))\n",
    "y_train = np.array(df_copy['y']).reshape(-1,)\n",
    "cross_val_score(mlp,X_train,y_train,cv=2,scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    \n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.SimpleRNN())\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse', \n",
    "              metrics=[coeff_determination])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tensorflow export\n",
    "features = ['askSize0','bidSize0']\n",
    "X_train = np.array(df[features]).reshape(-1,len(features))\n",
    "y_train = np.array(df['y']).reshape(-1,)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=3000)\n",
    "model.predict(np.array([0,1]).reshape(-1,2))[0][0]\n",
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
